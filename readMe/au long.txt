patent_novelty project

===========================
  DATA DOWNLOAD INSTRUCTIONS
===========================

1. Patent Compressed Data
--------------------------
Source:
https://huggingface.co/datasets/HUPD/hupd/tree/main/data

Download:
- Files for the years 2007–2016 (or select the years you need)


2. Vocabulary Files
--------------------
Sources:
- https://github.com/SerhadS/TechNet/tree/master/vocabulary
- https://github.com/SerhadS/TechNet/tree/master/additional_stopwords

Download:
- technical_stopwords.txt
- USPTO_stopwords_en.txt


3. Citations Data
------------------
Source:
https://patentsview.org/download/data-download-dictionary

Download:
- g_patent.tsv
- g_us_patent_citation.tsv


===========================
        FILE STRUCTURE
===========================

patent_novelty/
├── analysis/					# will contain final analysis of metrics
├── cd_index/					#
├── metricAnalysis/
├── metrics/
│   ├── ES/
│   ├── KS/
│   └── tE/
├── metrics_raw/
├── top10/
├── data/
│   ├── app_pat_match/
│   ├── citationsData/
│   │   ├── g_patent.tsv *                    	# Download required
│   │   └── g_us_patent_citation.tsv *        	# Download required
│   ├── compressedData/                       	# .tar.gz files (2007–2016) *
│   ├── csv_clean/
│   │   ├── ES/
│   │   ├── KS/
│   │   └── tE/
│   ├── csv_raw/
│   │   ├── ES/
│   │   │   └── text/
│   │   ├── KS/
│   │   └── tE/
│   ├── jsonData/
│   └── vocab/
│       ├── technet from github/
│       │   ├── vocab_github_1.tsv *          	# Download required
│       │   └── vocab_github_2.tsv *          	# Download required
│       └── vocab/
│           └── additional stopwords/
│               ├── manual_adds.txt           	# To download from GitHub
│               ├── technical_stopwords.txt * 	# Download required
│               └── USPTO_stopwords_en.txt *  	# Download required

* Asterisks indicate files to be downloaded manually.



# importation.py  
## Patent Data Preprocessing Tools

### Overview  
This module provides functions to preprocess patent application data from `.tar.gz` archives into clean, structured CSV files for evaluation and machine learning experiments.

---

### Main Functions

- **`tar_gz2json(listYear, pathData)`**  
  Extracts `.tar.gz` files for specified years into JSON format.

  **Parameters:**  
  - `listYear` (list of int): Years to uncompress.  
  - `pathData` (str): Path to the data directory containing subfolders such as `compressedData`, `jsonData`, etc.

- **`checkYears(year, yearsNeeded, pathData)`**  
  Verifies the availability and completeness of required past years' data for a given evaluation year.

  **Parameters:**  
  - `year` (int): Evaluation year.  
  - `yearsNeeded` (int): Number of past years needed for reference.  
  - `pathData` (str): Path to the data directory.

  **Returns:**  
  - `bool`: True if all required years are present and valid; False otherwise.

- **`json2toEval(year, listIPC, pathData, batch_size=1)`**  
  Creates labeled CSV files of patents for evaluation based on a given year and list of IPC codes. Also writes secondary IPC expectation files.

  **Parameters:**  
  - `year` (int): Year of patents to process.  
  - `listIPC` (list of str): IPC classes to filter main IPCs.  
  - `pathData` (str): Path to the data directory.  
  - `batch_size` (int, optional): Number of files to process per batch for progress display (default: 1).

  **Notes:**  
  Requires subdirectories `/tE/` and `/ES/text/` inside the raw CSV data path for storing outputs.

- **`json2_KS_ES(year, yearRef, listIPC, pathData)`**  
  Prepares training datasets from past years using Knowledge Space (KS) and Expectation Space (ES) methods.

  **Parameters:**  
  - `year` (int): Current evaluation year.  
  - `yearRef` (int): Reference year for training data.  
  - `listIPC` (list of str): IPC classes for filtering.  
  - `pathData` (str): Path to the data directory.

---

### Additional Details

- Utilizes libraries such as `os`, `pandas`, `json`, `tarfile`, and `tqdm` for file handling, JSON parsing, compression extraction, and progress visualization.
- Designed to handle large patent datasets spanning multiple years with batch processing.
- Validates data completeness before processing to ensure reliable machine learning inputs.


# cleaning.py  
## Text Cleaning and Lemmatization for Patent Data

### Overview  
This module provides tools to clean, tokenize, and lemmatize patent text data using a predefined vocabulary and lemmatization dictionary. It leverages spaCy for tokenization, NLTK for stopwords, and pandas for DataFrame handling, with progress tracking via tqdm.

---

### Main Components

- **Class `Vocab`**  
  Manages vocabulary creation, token filtering, and lemmatization for patent text.

  **Initialization parameters:**  
  - `technet` (DataFrame): Vocabulary terms dataset.  
  - `df_lemm` (DataFrame): Lemmatized technet data for filtering stopwords.  
  - `stopwords` (list): List of stopwords to exclude.

  **Key methods:**  
  - `setVocab()`: Extracts unique vocabulary terms from `technet`.  
  - `clean_tokens(text)`: Tokenizes input text and retains only tokens in the vocabulary.  
  - `cleanDF(df_text, type="all")`: Cleans specified sections (`background`, `claims`, `abstract`, `summary`) of a patent DataFrame.  
  - `lemmatize_with_dict(text)`: Lemmatizes a space-separated text string using a predefined dictionary.  
  - `lemmDF(df_clean)`: Applies lemmatization to all applicable columns in a cleaned DataFrame.  
  - `filterSW(df_lemm)`: Removes rows containing stopwords from a lemmatized DataFrame.

- **Function `get_file_names(pathCSV)`**  
  Returns a list of CSV file names within the given directory.

  **Parameters:**  
  - `pathCSV` (str): Path to the directory to search.

  **Returns:**  
  - List of CSV filenames or empty list if directory not found or no CSV files exist.

---

### Additional Notes

- Uses `spaCy` for tokenization with the English small model (`en_core_web_sm`).
- Downloads and utilizes NLTK stopwords to filter out common terms.
- Applies progress bars using `tqdm` for efficient tracking during batch processing.
- Designed for preprocessing patent texts in sections such as claims, background, abstract, and summary.



# divergences.py  
## Jensen-Shannon Divergence Module

### Overview  
This module provides a class `Jensen_Shannon` to compute Jensen-Shannon divergence (JSD) between two probability distributions. It supports weighted mixtures and normalizes inputs internally.

---

### Class: Jensen_Shannon

**Purpose:**  
Calculate the Jensen-Shannon divergence between two distributions \(P\) and \(Q\), which measures similarity between probability distributions.

**Init parameters:**  
- `Pi1` (float, default=0.5): Weight of the first distribution in the mixture.  
- `Pi2` (float, default=0.5): Weight of the second distribution; must satisfy `Pi1 + Pi2 = 1`.

**Methods:**  

- `linear_JSD(P, Q, cte=1e-10)`  
  Returns the Jensen-Shannon divergence per dimension as a list of values between vectors \(P\) and \(Q\).  
  Input vectors are normalized internally.

- `JSDiv(P, Q)`  
  Returns the scalar Jensen-Shannon divergence between vectors \(P\) and \(Q\).  
  Handles zero-sum vectors by substituting small epsilon values and normalizes the inputs.  
  Uses the relative entropy (Kullback-Leibler divergence) formulation.

---

### Notes  
- Inputs \(P\) and \(Q\) can be arrays or lists representing discrete probability distributions.  
- Jensen-Shannon divergence is symmetric and bounded, useful for comparing probability distributions.  
- The class asserts that the mixture weights sum to 1 during initialization.  
- Uses `scipy.special.rel_entr` and `numpy` for efficient computation.


novelty.py
# Novelty Metrics Module

## Overview

This module contains classes to compute novelty, uniqueness, and difference metrics on probability distributions (e.g., term distributions in patent texts).

Each class compares new or updated distributions to reference sets and returns divergence scores with flags indicating significant novelty or shifts.

---

## Classes

### Newness

**Purpose:**  
Compute novelty of a new distribution against a known reference by Jensen-Shannon divergence.

**Init parameters:**  
- `known_P` (array-like): Reference distribution  
- `new_Q` (array-like): New distribution  
- `lambda_` (float, optional): Weight factor (default=0.8)

**Main method:**  
- `divergent_terms(thr_div=0.0041, thr_new=0.5)`  
  Returns: `(novelty_score, novelty_flag)`  
  - `novelty_score`: proportion of divergent terms  
  - `novelty_flag`: 1 if novelty > threshold else 0

---

### Uniqueness

**Purpose:**  
Assess uniqueness or distributional shift of a new distribution against a prototype.

**Init parameters:**  
- `known_P` (array-like): Prototype distribution

**Main methods:**  
- `dist_to_proto(new_Q, thr_uniq=0.05)`  
  Returns: `(uniqueness_score, uniqueness_flag)`  
- `proto_dist_shift(new_P, thr_uniqp=0.05)`  
  Returns: `(shift_score, shift_flag)` for prototype updates
---

### Difference

**Purpose:**  
Estimate divergence of a new distribution from a list of known distributions.

**Init parameters:**  
- `list_know_P` (sparse matrix): Known distributions matrix  
- `new_Q` (numpy array): New distribution  
- `N` (int): Number of neighbors to consider

**Main methods:**  
- `dist_estimate(sample=True, sample_size=1000, do_sample_P=True)`  
  Returns: average Jensen-Shannon divergence from neighbors  
- `ratio_to_all(neighbor_dist, thr_diff=0.95)`  
  Returns: proportion of known distributions diverging above threshold

---

### ClusterKS (inherits Difference)

**Purpose:**  
Use KMeans clustering to efficiently find neighbors for novelty detection.

**Init parameters:**  
- Inherits from Difference  
- `nbPtsPerCluster` (int): points per cluster (approx.)

**Main methods:**  
- `clusterKS()`  
  Returns: (cluster_membership, KMeans_model)  
- `ratio_to_neighbors_kmeans(variation_dist, neighbor_dist=0, thr_diff=0.85, nb_clusters=4, spacyUpdated=False)`  
  Returns: novelty flag (0 or 1) based on divergence threshold in closest clusters


---

## Notes

- All divergence calculations use Jensen-Shannon divergence.  
- Inputs should be probability distributions (normalized vectors).  
- Threshold parameters (`thr_new_div`, `thr_diff`, `thr_uniq`, etc.) can be tuned based on application needs.  
- Supports sparse and dense input matrices.


# surprise.py  
## Surprise Metrics Module

### Overview  
This module computes surprise scores based on distributional shifts of PMI (Pointwise Mutual Information) bigrams between known and new data. It uses Jensen-Shannon divergence on PMI-based vectors to quantify how surprising new co-occurrences are compared to a baseline.

---

### Class: Surprise

**Purpose:**  
Calculate distributional surprise between two nested PMI dictionaries representing word co-occurrence scores.

**Init parameters:**  
- `pmi_new` (dict): New PMI scores as a dictionary of bigram tuples and their PMI values.

**Main methods:**  

- `get_common_vectors_adj(dict_old, dict_new, epsilon)`  
  Extracts common words’ PMI vectors from two nested dictionaries, filling missing values with `epsilon`.  
  Returns a dictionary mapping each word to a tuple of (old_vector, new_vector).

- `unique_surp_courte(newpmi_PMI, known_pmi, base_bigram_set, eps=0, thr_surp=0.)`  
  Computes an average Jensen-Shannon divergence surprise score between new and known PMI distributions over common bigrams.  
  Returns `(surprise_score, dist_surprise_flag)` where `dist_surprise_flag` is 1 if surprise > threshold.

- `new_surprise(pmi_known, thr_surp=0.0104)`  
  Measures surprise from the fraction of new PMI bigrams in the updated PMI not seen before.  
  Returns `(surprise_rate, new_surprise_flag)`.

---

### Notes  
- Uses Jensen-Shannon divergence imported from `novelty.divergences`.  
- PMI vectors are filtered and masked to avoid negative or zero values causing invalid divergence computations.  
- Thresholds (`thr_surp`) control when a change is flagged as surprising.  
- Suitable for large PMI dictionaries; some methods can be parallelized.  


# utils.py

This project provides a suite of utility functions and modules for analyzing textual data with a focus on **novelty detection**, **surprise analysis**, **vocabulary cleaning**, and **metric evaluation**. These tools are intended for processing large-scale technological or patent-related corpora across time and categories (e.g., IPC codes).

---


### Vocabulary Cleaning & Lemmatization

- **`createCleanTechnet(pathData)`**  
  Cleans raw Technet vocabulary by splitting multi-word terms and outputs a normalized list of terms to `clean_technet.csv`.

- **`lemmatizeTechnet(pathData)`**  
  Lemmatizes the cleaned vocabulary using spaCy and saves the result to `lemmatized_technet.csv`.

---

### Novelty & Metric Computation

- **`measureNov(...)`**  
  Computes novelty-related metrics (newness, uniqueness, difference, surprise) over multiple `(year, IPC)` combinations using co-occurrence patterns and statistical thresholds. Supports clustering for enhanced difference detection.

- **`compute_scores(...)`**  
  Core function that calculates innovation metrics for a given IPC-year context. Handles PMI-based surprise, distributional uniqueness, divergence-driven newness, and difference scoring.

---

### Surprise & PMI Analysis

- **`pmi(input_, w_size=3)`**  
  Calculates PMI scores for token bigrams within a specified window size.

- **`OptimizedIncrementalPMI`**  
  A class for efficient, incremental PMI calculation with support for updating co-occurrence statistics over time.

---

### Metric Evaluation & Statistical Analysis

- **`correl_labelScores(df)`**  
  Computes Pearson and Spearman correlations between binary `label` and various metric ratios (e.g., `new_ratio`, `uniq_ratio`).

- **`ttest_metric(df)`**  
  Applies Welch’s t-tests to compare novelty metrics between groups defined by the binary `label`.

- **`KTcorrel_metrics(df)`**  
  Computes Kendall Tau correlations between metrics, outputting a formatted triangular matrix.

---

## Additional Utilities

- Tokenization and n-gram extraction (`nltk`, `spacy`)
- Rank-Biased Overlap computation (`rbo`)
- Clustering support via `fast_cdindex`
- Statistical tools from `scipy.stats` and `statsmodels`
- Progress tracking (`tqdm`)
- JSON utilities and formatted data I/O

---







